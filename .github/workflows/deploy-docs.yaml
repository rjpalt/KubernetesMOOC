# Documentation deployment workflow - OpenAPI specs and coverage reports
name: Deploy Documentation to Pages

on:
  # Runs on pushes targeting the default branch
  push:
    branches: ["main"]
    paths:
      - 'course_project/**'

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

  # Runs after successful test workflow completion
  workflow_run:
    workflows: ["Test Pipeline - Microservices"]
    types: [completed]
    branches: ["main"]

# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages
permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.
# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.
concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  # Generate documentation from running services
  generate-docs:
    # Only run if test workflow succeeded or on manual trigger
    if: |
      github.event_name == 'workflow_dispatch' || 
      github.event_name == 'push' || 
      (github.event_name == 'workflow_run' && github.event.workflow_run.conclusion == 'success')
    
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Set up Python 3.13
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'
      
      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: "latest"
      
      # Start services to extract OpenAPI specs (no database needed)
      - name: Start microservices for OpenAPI extraction
        working-directory: course_project
        run: |
          echo "🚀 Starting services for OpenAPI spec extraction..."
          
          # Start backend service (FastAPI can generate OpenAPI without DB)
          cd todo-backend
          uv sync
          nohup uv run python -m src.main > backend.log 2>&1 &
          BACKEND_PID=$!
          echo $BACKEND_PID > backend.pid
          cd ..
          
          # Start frontend service  
          cd todo-app
          uv sync
          nohup uv run python -m src.main > frontend.log 2>&1 &
          FRONTEND_PID=$!
          echo $FRONTEND_PID > frontend.pid
          cd ..
          
          echo "⏳ Waiting for services to start..."
          
          # Wait for backend OpenAPI endpoint (not health, since that needs DB)
          for i in {1..30}; do
            if curl -s http://localhost:8001/openapi.json > /dev/null 2>&1; then
              echo "✅ Backend OpenAPI endpoint ready!"
              break
            fi
            echo "⏳ Attempt $i: Backend OpenAPI not ready yet..."
            sleep 2
          done
          
          # Wait for frontend OpenAPI endpoint
          for i in {1..30}; do
            if curl -s http://localhost:8000/openapi.json > /dev/null 2>&1; then
              echo "✅ Frontend OpenAPI endpoint ready!"
              break
            fi
            echo "⏳ Attempt $i: Frontend OpenAPI not ready yet..."
            sleep 2
          done
          
          echo "🎯 OpenAPI endpoints are ready for extraction!"
      
      # Create documentation structure
      - name: Create documentation structure
        run: |
          mkdir -p docs/{api,coverage,assets}
          mkdir -p docs/api/{todo-app,todo-backend}
          mkdir -p docs/coverage/{backend,frontend,combined}
      
      # Extract OpenAPI specifications
      - name: Extract OpenAPI specifications
        run: |
          echo "📋 Extracting OpenAPI specifications..."
          
          # Extract backend OpenAPI spec
          curl -s http://localhost:8001/openapi.json | jq '.' > docs/api/todo-backend/openapi.json
          
          # Extract frontend OpenAPI spec  
          curl -s http://localhost:8000/openapi.json | jq '.' > docs/api/todo-app/openapi.json
          
          echo "✅ OpenAPI specs extracted successfully"
      
      # Download coverage artifacts from test workflow
      - name: Download coverage artifacts
        if: github.event_name == 'workflow_run'
        uses: actions/download-artifact@v4
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ github.event.workflow_run.id }}
          path: coverage-artifacts/
      
      # Generate Swagger UI pages and documentation site
      - name: Generate documentation site
        run: |
          echo "📚 Generating documentation site..."
          
          # Download Swagger UI assets
          wget -q https://github.com/swagger-api/swagger-ui/archive/refs/tags/v5.10.3.tar.gz
          tar -xzf v5.10.3.tar.gz
          mkdir -p docs/assets
          cp -r swagger-ui-5.10.3/dist/* docs/assets/
          
          # Generate documentation using Python script
          python .github/scripts/generate-docs.py
          
          echo "✅ Documentation site generated"
      
      # Process coverage reports
      - name: Process coverage reports
        run: |
          echo "📊 Processing coverage reports..."
          
          if [ -d "coverage-artifacts" ]; then
            # Extract coverage files
            find coverage-artifacts -name "*.xml" -exec cp {} docs/coverage/ \;
            
            # Generate coverage badges (if coverage files exist)
            if command -v coverage-badge &> /dev/null; then
              for coverage_file in docs/coverage/*.xml; do
                if [ -f "$coverage_file" ]; then
                  service_name=$(basename "$coverage_file" .xml)
                  coverage-badge -f "$coverage_file" -o "docs/coverage/${service_name}-badge.svg" || true
                fi
              done
            fi
          else
            echo "ℹ️ No coverage artifacts found (running independently from test workflow)"
          fi
      
      # Cleanup services
      - name: Cleanup services
        if: always()
        working-directory: course_project
        run: |
          echo "🧹 Cleaning up services..."
          
          # Kill backend process
          if [ -f todo-backend/backend.pid ]; then
            kill $(cat todo-backend/backend.pid) 2>/dev/null || true
            rm todo-backend/backend.pid
          fi
          
          # Kill frontend process  
          if [ -f todo-app/frontend.pid ]; then
            kill $(cat todo-app/frontend.pid) 2>/dev/null || true
            rm todo-app/frontend.pid
          fi
          
          # Clean up any remaining processes on ports 8000/8001
          pkill -f "python -m src.main" || true
          
          echo "✅ Cleanup completed"
      
      - name: Setup Pages
        uses: actions/configure-pages@v5
      
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: './docs'
      
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
